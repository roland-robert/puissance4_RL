6000 per train (différé)
1700s/entrainement (6000)



class Hyperparameters:
    def __init__(self):
        self.lr = 0.04
        self.Qlr = 0
        self.gamma = 0.99

        self.eps = 0.99 #randomness
        self.min_eps = 0.05
        self.decay = 0.1

        #self.loss = tf.keras.losses.MeanSquaredError()
        self.loss = tf.keras.losses.Huber()
        self.metric=tf.keras.metrics.MeanSquaredError()

        self.maxmemlen = 20000
        #self.train_interval = 20 #etapes avant entrainement (etape = 1 coup)
        self.games_before_train = 1
        self.allow_illegal_moves = False

        #self.MIN_REPLAY_SIZE = 500
        self.batch_size = 16
        self.sample_size = 256
    def real_randomness(self, epoch):
         return self.min_eps + (self.eps - self.min_eps)*np.exp(-self.decay*epoch)

\\\\\\\\\\\\\\MODEL
        if model == 0:
            
            self.model = Sequential()
            self.model.add(layers.Conv2D(512, (4, 4), activation='relu', input_shape=(h, w, 3),
                  kernel_initializer=tf.keras.initializers.GlorotUniform(),
                  bias_initializer=tf.keras.initializers.Zeros()))
            self.model.add(layers.Flatten())
            self.model.add(layers.Dense(units = 256, activation = 'sigmoid', 
                  kernel_initializer=tf.keras.initializers.GlorotUniform(),
                  bias_initializer=tf.keras.initializers.Zeros()))
            self.model.add(layers.Dense(units = 256, activation = 'relu', 
                  kernel_initializer=tf.keras.initializers.GlorotUniform(),
                  bias_initializer=tf.keras.initializers.Zeros()))
            self.model.add(layers.Dense(units = w,bias_initializer=tf.keras.initializers.Zeros()))

            self.model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=self.hpp.lr), 
                   loss = self.hpp.loss,
                   metrics=[tf.keras.metrics.MeanSquaredError()])

